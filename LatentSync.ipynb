{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PREPARE ENVIRONMENT**\n",
        "- Due to changes in some dependencies, you will be prompted to restart the session after all the required libraries are installed. Simply restart and run this section again."
      ],
      "metadata": {
        "id": "QK_OVw3gVDCZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EpLZhSJmFMBJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "!pip install diffusers mediapipe transformers huggingface-hub omegaconf einops opencv-python face-alignment decord ffmpeg-python safetensors soundfile\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "if not os.path.exists(\"LatentSync\"):\n",
        "    !git clone https://github.com/Isi-dev/LatentSync\n",
        "%cd LatentSync\n",
        "\n",
        "from google.colab import files\n",
        "import torch\n",
        "from omegaconf import OmegaConf\n",
        "from diffusers import AutoencoderKL, DDIMScheduler\n",
        "from latentsync.models.unet import UNet3DConditionModel\n",
        "from latentsync.pipelines.lipsync_pipeline import LipsyncPipeline\n",
        "from latentsync.whisper.audio2feature import Audio2Feature\n",
        "from diffusers.utils.import_utils import is_xformers_available\n",
        "from accelerate.utils import set_seed\n",
        "import ipywidgets as widgets\n",
        "\n",
        "os.makedirs(\"/root/.cache/torch/hub/checkpoints\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "model_urls = {\n",
        "    \"/root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\":\n",
        "        \"https://huggingface.co/Isi99999/LatentSync/resolve/main/auxiliary/s3fd-619a316812.pth\",\n",
        "    \"/root/.cache/torch/hub/checkpoints/2DFAN4-cd938726ad.zip\":\n",
        "        \"https://huggingface.co/Isi99999/LatentSync/resolve/main/auxiliary/2DFAN4-cd938726ad.zip\",\n",
        "    \"checkpoints/latentsync_unet.pt\":\n",
        "        \"https://huggingface.co/Isi99999/LatentSync/resolve/main/latentsync_unet.pt\",\n",
        "    \"checkpoints/tiny.pt\":\n",
        "        \"https://huggingface.co/Isi99999/LatentSync/resolve/main/whisper/tiny.pt\",\n",
        "    \"checkpoints/diffusion_pytorch_model.safetensors\":\n",
        "        \"https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.safetensors\",\n",
        "    \"checkpoints/config.json\":\n",
        "        \"https://huggingface.co/stabilityai/sd-vae-ft-mse/raw/main/config.json\",\n",
        "}\n",
        "\n",
        "for file_path, url in model_urls.items():\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Downloading {file_path} ...\")\n",
        "        subprocess.run([\"wget\", url, \"-O\", file_path], check=True)\n",
        "    else:\n",
        "        print(f\"File {file_path} already exists. Skipping download.\")\n",
        "\n",
        "print(\"Setup complete.\")\n",
        "\n",
        "def perform_inference(video_path, audio_path, seed=1247, num_inference_steps=20, guidance_scale=1.0, output_path=\"output_video.mp4\"):\n",
        "    config_path = \"configs/unet/first_stage.yaml\"\n",
        "    inference_ckpt_path = \"checkpoints/latentsync_unet.pt\"\n",
        "\n",
        "    config = OmegaConf.load(config_path)\n",
        "\n",
        "    is_fp16_supported = torch.cuda.is_available() and torch.cuda.get_device_capability()[0] > 7\n",
        "    dtype = torch.float16 if is_fp16_supported else torch.float32\n",
        "\n",
        "    scheduler = DDIMScheduler.from_pretrained(\"configs\")\n",
        "\n",
        "    whisper_model_path = \"checkpoints/tiny.pt\"\n",
        "    audio_encoder = Audio2Feature(model_path=whisper_model_path, device=\"cuda\", num_frames=config.data.num_frames)\n",
        "\n",
        "    vae = AutoencoderKL.from_pretrained(\"checkpoints\", torch_dtype=dtype, local_files_only=True)\n",
        "    vae.config.scaling_factor = 0.18215\n",
        "    vae.config.shift_factor = 0\n",
        "\n",
        "    unet, _ = UNet3DConditionModel.from_pretrained(\n",
        "        OmegaConf.to_container(config.model),\n",
        "        inference_ckpt_path,\n",
        "        device=\"cpu\",\n",
        "    )\n",
        "\n",
        "    unet = unet.to(dtype=dtype)\n",
        "\n",
        "    if is_xformers_available():\n",
        "        unet.enable_xformers_memory_efficient_attention()\n",
        "        print('x_formers available!')\n",
        "\n",
        "    pipeline = LipsyncPipeline(\n",
        "        vae=vae,\n",
        "        audio_encoder=audio_encoder,\n",
        "        unet=unet,\n",
        "        scheduler=scheduler,\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    set_seed(seed)\n",
        "\n",
        "    pipeline(\n",
        "        video_path=video_path,\n",
        "        audio_path=audio_path,\n",
        "        video_out_path=output_path,\n",
        "        video_mask_path=output_path.replace(\".mp4\", \"_mask.mp4\"),\n",
        "        num_frames=config.data.num_frames,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        weight_dtype=dtype,\n",
        "        width=config.data.resolution,\n",
        "        height=config.data.resolution,\n",
        "    )\n",
        "    return output_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN IMAGE TO VIDEO**"
      ],
      "metadata": {
        "id": "FQe7fJHzbOmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import cv2\n",
        "import torchaudio\n",
        "import subprocess\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "        import gc\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "        gc.collect()\n",
        "\n",
        "image_upload = widgets.FileUpload(accept=\"image/*\", multiple=False, description=\"Upload Image\")\n",
        "audio_upload = widgets.FileUpload(accept=\".wav,.mp3,.aac,.flac\", multiple=False, description=\"Upload Audio\")\n",
        "seed_input = widgets.IntText(value=1247, description=\"Seed:\")\n",
        "num_steps_input = widgets.IntSlider(value=20, min=1, max=100, step=1, description=\"Steps:\")\n",
        "guidance_scale_input = widgets.FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description=\"Guidance Scale:\")\n",
        "video_scale_input = widgets.FloatSlider(value=0.5, min=0.1, max=1.0, step=0.1, description=\"Video Scale:\")\n",
        "output_fps_input = widgets.IntSlider(value=25, min=6, max=60, step=1, description=\"Output FPS:\")\n",
        "\n",
        "run_button = widgets.Button(description=\"Run Inference\")\n",
        "output_display = widgets.Output()\n",
        "\n",
        "def convert_video_fps(input_path, target_fps):\n",
        "    if not os.path.exists(input_path) or os.path.getsize(input_path) == 0:\n",
        "        print(f\"Error: The video file {input_path} is missing or empty.\")\n",
        "        return None\n",
        "\n",
        "    output_path = f\"converted_{target_fps}fps.mp4\"\n",
        "\n",
        "    audio_check_cmd = [\n",
        "        \"ffprobe\", \"-i\", input_path, \"-show_streams\", \"-select_streams\", \"a\",\n",
        "        \"-loglevel\", \"error\"\n",
        "    ]\n",
        "    audio_present = subprocess.run(audio_check_cmd, capture_output=True, text=True).stdout.strip() != \"\"\n",
        "\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\", \"-i\", input_path,\n",
        "        \"-filter:v\", f\"fps={target_fps}\",\n",
        "        \"-c:v\", \"libx264\", \"-preset\", \"fast\", \"-crf\", \"18\",\n",
        "    ]\n",
        "\n",
        "    if audio_present:\n",
        "        cmd.extend([\"-c:a\", \"aac\", \"-b:a\", \"192k\"])\n",
        "    else:\n",
        "        cmd.append(\"-an\")\n",
        "\n",
        "    cmd.append(output_path)\n",
        "\n",
        "    subprocess.run(cmd, check=True)\n",
        "    print(f\"Converted video saved as {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# def add_silent_frames(audio_path, target_fps=25):\n",
        "\n",
        "#     waveform, sample_rate = torchaudio.load(audio_path)\n",
        "#     silent_duration = 25 / target_fps  # Two frames at target FPS\n",
        "#     silent_samples = int(silent_duration * sample_rate)\n",
        "#     silent_waveform = torch.zeros((waveform.shape[0], silent_samples))\n",
        "\n",
        "#     # Concatenate silence at the beginning for mouth correction\n",
        "#     new_waveform = torch.cat((silent_waveform, waveform), dim=1)\n",
        "#     new_audio_path = \"audio_with_silence.wav\"\n",
        "#     torchaudio.save(new_audio_path, new_waveform, sample_rate)\n",
        "\n",
        "#     return new_audio_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def pad_audio_to_multiple_of_16(audio_path, target_fps=25):\n",
        "\n",
        "    # audio_path = add_silent_frames(audio_path)\n",
        "\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    audio_duration = waveform.shape[1] / sample_rate  # Duration in seconds\n",
        "\n",
        "    num_frames = int(audio_duration * target_fps)\n",
        "\n",
        "    # Pad audio to ensure frame count is a multiple of 16\n",
        "    remainder = num_frames % 16\n",
        "    if remainder > 0:\n",
        "        pad_frames = 16 - remainder\n",
        "        pad_samples = int((pad_frames / target_fps) * sample_rate)\n",
        "        pad_waveform = torch.zeros((waveform.shape[0], pad_samples))  # Silence padding\n",
        "        waveform = torch.cat((waveform, pad_waveform), dim=1)\n",
        "\n",
        "        # Save the padded audio\n",
        "        padded_audio_path = \"padded_audio.wav\"\n",
        "        torchaudio.save(padded_audio_path, waveform, sample_rate)\n",
        "    else:\n",
        "        padded_audio_path = audio_path  # No padding needed\n",
        "\n",
        "    padded_duration = waveform.shape[1] / sample_rate\n",
        "    padded_num_frames = int(padded_duration * target_fps)\n",
        "\n",
        "    return padded_audio_path, padded_num_frames\n",
        "\n",
        "\n",
        "\n",
        "def create_video_from_image(image_path, output_video_path, num_frames, fps=25):\n",
        "    \"\"\"Convert an image into a video of specified length (num_frames at 25 FPS).\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"Error: Unable to read the image.\")\n",
        "        return None\n",
        "\n",
        "    height, width, _ = img.shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for _ in range(num_frames):\n",
        "        video_writer.write(img)\n",
        "\n",
        "    video_writer.release()\n",
        "    print(f\"Created video {output_video_path} with {num_frames} frames ({num_frames / fps:.2f} seconds).\")\n",
        "    return output_video_path\n",
        "\n",
        "\n",
        "def on_run_button_click(change):\n",
        "    with output_display:\n",
        "        output_display.clear_output()\n",
        "\n",
        "        # Validate uploads\n",
        "        if not audio_upload.value or not image_upload.value:\n",
        "            print(\"Please upload both an image and an audio file.\")\n",
        "            return\n",
        "\n",
        "        # Process audio\n",
        "        audio_file_info = next(iter(audio_upload.value.values()))\n",
        "        audio_path = audio_file_info.get('name', 'uploaded_audio.wav')\n",
        "        with open(audio_path, \"wb\") as f:\n",
        "            f.write(audio_file_info['content'])\n",
        "\n",
        "        # Get audio duration with padding\n",
        "        audio_path, num_frames = pad_audio_to_multiple_of_16(audio_path, target_fps=25)\n",
        "\n",
        "        # Process image and create video\n",
        "        image_file_info = next(iter(image_upload.value.values()))\n",
        "        image_path = image_file_info.get('name', 'uploaded_image.png')\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(image_file_info['content'])\n",
        "\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(\"Error: Could not read the image file.\")\n",
        "            return\n",
        "\n",
        "        height, width, _ = img.shape\n",
        "        video_path = \"generated_video.mp4\"\n",
        "        video_path = create_video_from_image(image_path, video_path, num_frames)\n",
        "\n",
        "        try:\n",
        "            print(\"Running inference...\")\n",
        "            output_path = \"output_video.mp4\"\n",
        "            perform_inference(video_path, audio_path, seed_input.value, num_steps_input.value, guidance_scale_input.value, output_path)\n",
        "\n",
        "            output_path = convert_video_fps(output_path, output_fps_input.value)\n",
        "\n",
        "            from IPython.display import Video\n",
        "            print(\"Inference complete. Displaying output video:\")\n",
        "            display(Video(output_path, embed=True, width=int(width * video_scale_input.value), height=int(height * video_scale_input.value)))\n",
        "\n",
        "        finally:\n",
        "            torch.cuda.empty_cache()\n",
        "            for path in [video_path, audio_path, image_path]:\n",
        "                if path and os.path.exists(path):\n",
        "                    os.remove(path)\n",
        "\n",
        "run_button.on_click(on_run_button_click)\n",
        "\n",
        "# Display the UI\n",
        "widgets_box = widgets.VBox([\n",
        "    image_upload, audio_upload,\n",
        "    seed_input, num_steps_input, guidance_scale_input, video_scale_input,\n",
        "    output_fps_input, run_button, output_display\n",
        "])\n",
        "display(widgets_box)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t0fOMU7dZ4Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN VIDEO TO VIDEO**\n",
        "- If the input video is shorter than the audio, it will be looped to match the audio's length. To make the video play in reverse order after reaching the end, check the `loop_vid_from_endframe` box. If the input video is already a seamless loop, leave this box unchecked."
      ],
      "metadata": {
        "id": "5SZG7y6OVOQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "if torch.cuda.is_available():\n",
        "        import gc\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "        gc.collect()\n",
        "import ipywidgets as widgets\n",
        "import torch\n",
        "import torchaudio\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "import os\n",
        "import ffmpeg\n",
        "loop_vid_from_endframe = True # @param {\"type\":\"boolean\"}\n",
        "\n",
        "def convert_video_fps(input_path, target_fps):\n",
        "    if not os.path.exists(input_path) or os.path.getsize(input_path) == 0:\n",
        "        print(f\"Error: The video file {input_path} is missing or empty.\")\n",
        "        return None\n",
        "\n",
        "    output_path = f\"converted_{target_fps}fps.mp4\"\n",
        "\n",
        "    audio_check_cmd = [\n",
        "        \"ffprobe\", \"-i\", input_path, \"-show_streams\", \"-select_streams\", \"a\",\n",
        "        \"-loglevel\", \"error\"\n",
        "    ]\n",
        "    audio_present = subprocess.run(audio_check_cmd, capture_output=True, text=True).stdout.strip() != \"\"\n",
        "\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\", \"-i\", input_path,\n",
        "        \"-filter:v\", f\"fps={target_fps}\",\n",
        "        \"-c:v\", \"libx264\", \"-preset\", \"fast\", \"-crf\", \"18\",\n",
        "    ]\n",
        "\n",
        "    if audio_present:\n",
        "        cmd.extend([\"-c:a\", \"aac\", \"-b:a\", \"192k\"])\n",
        "    else:\n",
        "        cmd.append(\"-an\")\n",
        "\n",
        "    cmd.append(output_path)\n",
        "\n",
        "    subprocess.run(cmd, check=True)\n",
        "    print(f\"Converted video saved as {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def trim_video(video_path, target_duration):\n",
        "    if not os.path.exists(video_path) or os.path.getsize(video_path) == 0:\n",
        "        print(f\"Error: The video file {video_path} is missing or empty.\")\n",
        "        return video_path\n",
        "\n",
        "    has_audio = False\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', select_streams='a:0', show_entries='stream=codec_type')\n",
        "        has_audio = any(stream['codec_type'] == 'audio' for stream in probe['streams'])\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"Error while probing video: {e}\")\n",
        "        return video_path\n",
        "\n",
        "    trimmed_video_path = \"trimmed_video.mp4\"\n",
        "    try:\n",
        "        if has_audio:\n",
        "            ffmpeg.input(video_path, ss=0, to=target_duration).output(trimmed_video_path, codec=\"libx264\", audio_codec=\"aac\").run()\n",
        "        else:\n",
        "            ffmpeg.input(video_path, ss=0, to=target_duration).output(trimmed_video_path, codec=\"libx264\").run()\n",
        "        print(\"Video trimmed\")\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"Error during video trimming: {e}\")\n",
        "        return video_path\n",
        "\n",
        "    return trimmed_video_path\n",
        "\n",
        "\n",
        "def has_audio(video_path):\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', select_streams='a', show_entries='stream=index')\n",
        "        return len(probe['streams']) > 0\n",
        "    except ffmpeg.Error:\n",
        "        return False\n",
        "\n",
        "def extend_video(video_path, target_duration):\n",
        "    if not os.path.exists(video_path) or os.path.getsize(video_path) == 0:\n",
        "        print(f\"Error: The video file {video_path} is missing or empty.\")\n",
        "        return video_path\n",
        "\n",
        "    audio_exists = has_audio(video_path)\n",
        "\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', select_streams='v:0', show_entries='format=duration')\n",
        "        original_duration = float(probe['format']['duration'])\n",
        "    except ffmpeg.Error as e:\n",
        "        error_message = e.stderr.decode() if e.stderr else \"No error message available\"\n",
        "        print(f\"Error: Unable to fetch video duration: {error_message}\")\n",
        "        # print(f\"Error: Unable to fetch video duration: {e.stderr.decode()}\")\n",
        "        return video_path\n",
        "\n",
        "    if original_duration <= 0:\n",
        "        print(\"Error: Invalid video duration!\")\n",
        "        return video_path\n",
        "\n",
        "    print(\"Extending video...\")\n",
        "\n",
        "    clips = [video_path]\n",
        "    total_duration = original_duration\n",
        "    extensions = 0\n",
        "\n",
        "    while total_duration < target_duration:\n",
        "        extensions += 1\n",
        "        if loop_vid_from_endframe:\n",
        "            reversed_clip = reverse_video(clips[-1], audio_exists)\n",
        "            clips.append(reversed_clip)\n",
        "        else:\n",
        "            clips.append(clips[-1])\n",
        "            # new_clip = f\"copy_{extensions}_{os.path.basename(clips[-1])}\"\n",
        "            # shutil.copy(clips[-1], new_clip)\n",
        "            # clips.append(new_clip)\n",
        "        total_duration += original_duration\n",
        "\n",
        "    print(f\"The video was extended {extensions} time(s)\")\n",
        "\n",
        "    extended_video_path = \"extended_video.mp4\"\n",
        "\n",
        "    try:\n",
        "        inputs = [ffmpeg.input(clip) for clip in clips]\n",
        "\n",
        "        if audio_exists:\n",
        "            concat = ffmpeg.concat(*inputs, v=1, a=1).output(extended_video_path, codec=\"libx264\", audio_codec=\"aac\", format=\"mp4\", vcodec=\"libx264\", acodec=\"aac\")\n",
        "        else:\n",
        "            concat = ffmpeg.concat(*inputs, v=1, a=0).output(extended_video_path, codec=\"libx264\", format=\"mp4\", vcodec=\"libx264\")\n",
        "\n",
        "        concat.run(overwrite_output=True)\n",
        "    except ffmpeg.Error as e:\n",
        "        error_message = e.stderr.decode() if e.stderr else \"No error message available\"\n",
        "        print(f\"Error during video concatenation: {error_message}\")\n",
        "        return video_path\n",
        "\n",
        "    for clip in clips[1:]:\n",
        "        if os.path.exists(clip):\n",
        "            os.remove(clip)\n",
        "\n",
        "    return extended_video_path\n",
        "\n",
        "\n",
        "def reverse_video(video_path, audio_exists):\n",
        "\n",
        "    # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Format: YYYYMMDD_HHMMSS\n",
        "    reversed_video_path = f\"reversed_{os.path.basename(video_path)}\"\n",
        "    # reversed_video_path = os.path.join(\n",
        "    #     os.path.dirname(video_path),\n",
        "    #     f\"r_{timestamp}_{os.path.basename(video_path)}\"\n",
        "    # )\n",
        "    try:\n",
        "        if audio_exists:\n",
        "            ffmpeg.input(video_path).output(reversed_video_path, vf='reverse', af='areverse').run(overwrite_output=True)\n",
        "        else:\n",
        "            ffmpeg.input(video_path).output(reversed_video_path, vf='reverse').run(overwrite_output=True)\n",
        "    except ffmpeg.Error as e:\n",
        "        error_message = e.stderr.decode() if e.stderr else \"No error message available\"\n",
        "        print(f\"Error during video reversal: {error_message}\")\n",
        "        return video_path\n",
        "\n",
        "    return reversed_video_path\n",
        "\n",
        "\n",
        "def get_video_duration(video_path):\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', select_streams='v:0', show_entries='format=duration')\n",
        "        return float(probe['format']['duration'])\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"Error: Unable to fetch video duration for {video_path}: {e}\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def pad_audio_to_multiple_of_16(audio_path, target_fps=25):\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    audio_duration = waveform.shape[1] / sample_rate\n",
        "    num_frames = int(audio_duration * target_fps)\n",
        "    remainder = num_frames % 16\n",
        "\n",
        "    if remainder > 0:\n",
        "        pad_frames = 16 - remainder\n",
        "        pad_samples = int((pad_frames / target_fps) * sample_rate)\n",
        "        pad_waveform = torch.zeros((waveform.shape[0], pad_samples))\n",
        "        waveform = torch.cat((waveform, pad_waveform), dim=1)\n",
        "        padded_audio_path = \"padded_audio.wav\"\n",
        "        torchaudio.save(padded_audio_path, waveform, sample_rate)\n",
        "    else:\n",
        "        padded_audio_path = audio_path\n",
        "\n",
        "    return padded_audio_path, int((waveform.shape[1] / sample_rate) * target_fps), waveform.shape[1] / sample_rate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Rewriting some functions\n",
        "\n",
        "def trim_video(video_path, target_duration):\n",
        "    \"\"\"Trim video to specified duration with robust error handling\"\"\"\n",
        "    # Validate input file\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Error: Video file not found at {video_path}\")\n",
        "        return video_path\n",
        "    if os.path.getsize(video_path) == 0:\n",
        "        print(f\"Error: Video file is empty at {video_path}\")\n",
        "        return video_path\n",
        "    if target_duration <= 0:\n",
        "        print(f\"Error: Invalid target duration {target_duration}\")\n",
        "        return video_path\n",
        "\n",
        "    # Get original duration for validation\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', show_entries='format=duration')\n",
        "        original_duration = float(probe['format']['duration'])\n",
        "        if original_duration <= 0:\n",
        "            print(\"Error: Could not determine valid video duration\")\n",
        "            return video_path\n",
        "\n",
        "        print(f\"Original duration: {original_duration:.2f}s, Target duration: {target_duration:.2f}s\")\n",
        "\n",
        "        if original_duration <= target_duration:\n",
        "            print(\"Video is already shorter than target duration, no trimming needed\")\n",
        "            return video_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error probing video duration: {str(e)}\")\n",
        "        return video_path\n",
        "\n",
        "    # Check for audio stream more robustly\n",
        "    has_audio = False\n",
        "    try:\n",
        "        audio_probe = ffmpeg.probe(\n",
        "            video_path,\n",
        "            v='error',\n",
        "            select_streams='a',\n",
        "            show_entries='stream=codec_type,codec_name'\n",
        "        )\n",
        "        has_audio = any(stream['codec_type'] == 'audio' for stream in audio_probe.get('streams', []))\n",
        "        if has_audio:\n",
        "            audio_codec = audio_probe['streams'][0]['codec_name']\n",
        "            print(f\"Detected audio stream with codec: {audio_codec}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not determine audio status: {str(e)}\")\n",
        "\n",
        "    # Prepare output path with timestamp to avoid conflicts\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    trimmed_video_path = f\"trimmed_{timestamp}.mp4\"\n",
        "\n",
        "    # Build ffmpeg command\n",
        "    try:\n",
        "        input_stream = ffmpeg.input(video_path, ss=0, to=target_duration)\n",
        "\n",
        "        output_args = {\n",
        "            'c:v': 'libx264',\n",
        "            'preset': 'fast',\n",
        "            'crf': '18',\n",
        "            'pix_fmt': 'yuv420p',\n",
        "            'movflags': '+faststart'  # For web optimization\n",
        "        }\n",
        "\n",
        "        if has_audio:\n",
        "            output_args['c:a'] = 'aac'\n",
        "            output_args['b:a'] = '192k'\n",
        "            output_args['ar'] = '44100'\n",
        "            output_args['ac'] = '2'  # Stereo audio\n",
        "\n",
        "        # Use subprocess for better error handling\n",
        "        cmd = (\n",
        "            input_stream\n",
        "            .output(trimmed_video_path, **output_args)\n",
        "            .compile()\n",
        "        )\n",
        "\n",
        "        # print(f\"Running command: {' '.join(cmd)}\")\n",
        "\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            check=True,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        print(\"Video trimmed successfully\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"FFmpeg trimming failed with error:\\n{e.stderr}\")\n",
        "        # Clean up potentially partial output file\n",
        "        if os.path.exists(trimmed_video_path):\n",
        "            try:\n",
        "                os.remove(trimmed_video_path)\n",
        "            except Exception as clean_err:\n",
        "                print(f\"Warning: Could not clean up failed output: {str(clean_err)}\")\n",
        "        return video_path\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error during trimming: {str(e)}\")\n",
        "        return video_path\n",
        "\n",
        "    # Verify output\n",
        "    if not os.path.exists(trimmed_video_path):\n",
        "        print(\"Error: Trimmed video file was not created\")\n",
        "        return video_path\n",
        "\n",
        "    if os.path.getsize(trimmed_video_path) == 0:\n",
        "        print(\"Error: Trimmed video file is empty\")\n",
        "        os.remove(trimmed_video_path)\n",
        "        return video_path\n",
        "\n",
        "    try:\n",
        "        output_duration = float(ffmpeg.probe(trimmed_video_path)['format']['duration'])\n",
        "        duration_diff = abs(output_duration - target_duration)\n",
        "        if duration_diff > 0.5:  # Allow 0.5s tolerance\n",
        "            print(f\"Warning: Trimmed duration is {output_duration:.2f}s (target: {target_duration:.2f}s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not verify output duration: {str(e)}\")\n",
        "\n",
        "    return trimmed_video_path\n",
        "\n",
        "def extend_video(video_path, target_duration):\n",
        "    if not os.path.exists(video_path) or os.path.getsize(video_path) == 0:\n",
        "        print(f\"Error: The video file {video_path} is missing or empty.\")\n",
        "        return video_path\n",
        "\n",
        "    # Check audio existence more robustly\n",
        "    audio_exists = has_audio(video_path)\n",
        "    print(f\"Audio exists in source: {audio_exists}\")\n",
        "\n",
        "    # Get original duration with verification\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', select_streams='v:0', show_entries='format=duration')\n",
        "        original_duration = float(probe['format']['duration'])\n",
        "        print(f\"Original duration: {original_duration:.2f}s, Target duration: {target_duration:.2f}s\")\n",
        "\n",
        "        if original_duration <= 0:\n",
        "            raise ValueError(\"Invalid video duration detected\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting video duration: {str(e)}\")\n",
        "        return video_path\n",
        "\n",
        "    # Calculate needed extensions\n",
        "    if original_duration >= target_duration:\n",
        "        print(\"Video already meets target duration\")\n",
        "        return video_path\n",
        "\n",
        "    clips = [video_path]\n",
        "    total_duration = original_duration\n",
        "    extensions = 0\n",
        "\n",
        "    # Create extended clips\n",
        "    while total_duration < target_duration:\n",
        "        extensions += 1\n",
        "        try:\n",
        "            if loop_vid_from_endframe:\n",
        "                reversed_clip = reverse_video(clips[-1], audio_exists)\n",
        "                if not os.path.exists(reversed_clip) or os.path.getsize(reversed_clip) == 0:\n",
        "                    raise Exception(\"Reversed clip creation failed\")\n",
        "                clips.append(reversed_clip)\n",
        "                # print(f\"Created reversed clip: {reversed_clip}\")\n",
        "            else:\n",
        "                clips.append(clips[-1])\n",
        "\n",
        "            total_duration += original_duration\n",
        "            # print(f\"Extended to {total_duration:.2f}s (iteration {extensions})\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed during clip extension: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    # Verify we actually extended the video\n",
        "    if len(clips) <= 1:\n",
        "        print(\"No extension performed, returning original\")\n",
        "        return video_path\n",
        "\n",
        "    # Check all clips before concatenation\n",
        "    print(\"\\nClip properties before concatenation:\")\n",
        "    for i, clip in enumerate(clips):\n",
        "        try:\n",
        "            probe = ffmpeg.probe(clip)\n",
        "            # print(f\"Clip {i+1}: {os.path.basename(clip)}\")\n",
        "            # print(f\"  Size: {os.path.getsize(clip)/1024/1024:.2f}MB\")\n",
        "            for stream in probe['streams']:\n",
        "                if stream['codec_type'] == 'video':\n",
        "                    print(f\"  Video: {stream['codec_name']} {stream['width']}x{stream['height']}\")\n",
        "                elif stream['codec_type'] == 'audio':\n",
        "                    print(f\"  Audio: {stream['codec_name']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error checking clip {clip}: {str(e)}\")\n",
        "            return video_path\n",
        "\n",
        "    # Concatenation using demuxer method (most reliable)\n",
        "    extended_video_path = \"extended_video.mp4\"\n",
        "    concat_list_path = \"concat_list.txt\"\n",
        "\n",
        "    try:\n",
        "        # Create concat list file\n",
        "        with open(concat_list_path, 'w') as f:\n",
        "            for clip in clips:\n",
        "                f.write(f\"file '{os.path.abspath(clip)}'\\n\")\n",
        "\n",
        "        # Build ffmpeg command\n",
        "        cmd = [\n",
        "            'ffmpeg', '-y',\n",
        "            '-f', 'concat',\n",
        "            '-safe', '0',\n",
        "            '-i', concat_list_path,\n",
        "            '-c', 'copy'  # Stream copy (no re-encoding)\n",
        "        ]\n",
        "\n",
        "        # For some formats, we need to force MP4 output\n",
        "        if not extended_video_path.endswith('.mp4'):\n",
        "            cmd.extend(['-f', 'mp4'])\n",
        "\n",
        "        cmd.append(extended_video_path)\n",
        "\n",
        "        # Run command with error capture\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            check=True,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True\n",
        "        )\n",
        "        print(\"Concatenation successful!\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Concatenation failed with error:\\n{e.stderr}\")\n",
        "        return video_path\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error during concatenation: {str(e)}\")\n",
        "        return video_path\n",
        "    finally:\n",
        "        # Cleanup temporary files\n",
        "        if os.path.exists(concat_list_path):\n",
        "            os.remove(concat_list_path)\n",
        "\n",
        "        # Remove intermediate reversed clips\n",
        "        for clip in clips[1:]:\n",
        "            if os.path.exists(clip):\n",
        "                try:\n",
        "                    os.remove(clip)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not remove {clip}: {str(e)}\")\n",
        "\n",
        "    # Verify output\n",
        "    if not os.path.exists(extended_video_path) or os.path.getsize(extended_video_path) == 0:\n",
        "        print(\"Error: Final extended video not created properly\")\n",
        "        return video_path\n",
        "\n",
        "    final_duration = get_video_duration(extended_video_path)\n",
        "    print(f\"Final extended duration: {final_duration:.2f}s\")\n",
        "\n",
        "    return extended_video_path\n",
        "\n",
        "\n",
        "def reverse_video(video_path, audio_exists):\n",
        "    \"\"\"Create a reversed version of the video\"\"\"\n",
        "    reversed_path = f\"reversed_{os.path.basename(video_path)}\"\n",
        "    try:\n",
        "        if audio_exists:\n",
        "            (\n",
        "                ffmpeg.input(video_path)\n",
        "                .output(reversed_path, vf='reverse', af='areverse')\n",
        "                .run(overwrite_output=True, capture_stdout=True, capture_stderr=True)\n",
        "            )\n",
        "        else:\n",
        "            (\n",
        "                ffmpeg.input(video_path)\n",
        "                .output(reversed_path, vf='reverse')\n",
        "                .run(overwrite_output=True, capture_stdout=True, capture_stderr=True)\n",
        "            )\n",
        "        return reversed_path\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"Reverse failed: {e.stderr.decode()}\")\n",
        "        raise\n",
        "\n",
        "def has_audio(video_path):\n",
        "    \"\"\"Check if video contains audio stream\"\"\"\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', select_streams='a')\n",
        "        return len(probe['streams']) > 0\n",
        "    except ffmpeg.Error:\n",
        "        return False\n",
        "\n",
        "def get_video_duration(video_path):\n",
        "    \"\"\"Get duration in seconds\"\"\"\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path, v='error', select_streams='v:0', show_entries='format=duration')\n",
        "        return float(probe['format']['duration'])\n",
        "    except Exception as e:\n",
        "        print(f\"Duration check failed: {str(e)}\")\n",
        "        return 0\n",
        "# End of new functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "video_upload = widgets.FileUpload(accept=\".mp4\", multiple=False, description=\"Upload Video\")\n",
        "audio_upload = widgets.FileUpload(accept=\".wav,.mp3,.aac,.flac\", multiple=False, description=\"Upload Audio\")\n",
        "seed_input = widgets.IntText(value=1247, description=\"Seed:\")\n",
        "num_steps_input = widgets.IntSlider(value=20, min=1, max=100, step=1, description=\"Steps:\")\n",
        "guidance_scale_input = widgets.FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description=\"Guidance Scale:\")\n",
        "video_scale_input = widgets.FloatSlider(value=0.5, min=0.1, max=1.0, step=0.1, description=\"Video Scale:\")\n",
        "output_fps_input = widgets.IntSlider(value=25, min=6, max=60, step=1, description=\"Output FPS:\")\n",
        "width, height = 0, 0\n",
        "\n",
        "run_button = widgets.Button(description=\"Run Inference\")\n",
        "output_display = widgets.Output()\n",
        "\n",
        "def on_run_button_click(change):\n",
        "    with output_display:\n",
        "        output_display.clear_output()\n",
        "\n",
        "        print(\"Checking Video...\")\n",
        "        if not video_upload.value or not audio_upload.value:\n",
        "            print(\"Please upload both video and audio files.\")\n",
        "            return\n",
        "\n",
        "\n",
        "        video_file_info = next(iter(video_upload.value.values()))\n",
        "        video_path = \"uploaded_video.mp4\"\n",
        "        with open(video_path, \"wb\") as f:\n",
        "            f.write(video_file_info['content'])\n",
        "\n",
        "        global width, height\n",
        "        if width <= 0 or height <= 0:\n",
        "            print(\"Setting output video's width & height.\")\n",
        "            import cv2\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            if cap.isOpened():\n",
        "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            else:\n",
        "                print(\"Error: Unable to open video file.\")\n",
        "            cap.release()\n",
        "\n",
        "        # print(\"Uploading Audio...\")\n",
        "        audio_file_info = next(iter(audio_upload.value.values()))\n",
        "        audio_path = \"uploaded_audio.mp3\"\n",
        "        with open(audio_path, \"wb\") as f:\n",
        "            f.write(audio_file_info['content'])\n",
        "\n",
        "        video_path = convert_video_fps(video_path, 25)\n",
        "\n",
        "        audio_path, num_frames, audio_duration = pad_audio_to_multiple_of_16(audio_path, target_fps=25)\n",
        "\n",
        "\n",
        "        video_duration = get_video_duration (video_path)\n",
        "\n",
        "        if audio_duration > video_duration:\n",
        "            video_path = extend_video(video_path, audio_duration)\n",
        "            video_duration = get_video_duration (video_path)\n",
        "            if video_duration > audio_duration:\n",
        "                video_path = trim_video(video_path, audio_duration)\n",
        "\n",
        "        elif video_duration > audio_duration:\n",
        "            video_path = trim_video(video_path, audio_duration)\n",
        "\n",
        "        try:\n",
        "            print(\"Running inference...\")\n",
        "            output_path = \"output_video.mp4\"\n",
        "            perform_inference(video_path, audio_path, seed_input.value, num_steps_input.value, guidance_scale_input.value, output_path)\n",
        "\n",
        "            output_path = convert_video_fps(output_path, output_fps_input.value)\n",
        "\n",
        "            print(\"Inference complete. Displaying output video:\")\n",
        "            from IPython.display import Video\n",
        "            if width <= 0 :\n",
        "                display(Video(output_path, embed=True))\n",
        "            else:\n",
        "                display(Video(output_path, embed=True, width=int(width * video_scale_input.value), height=int(height * video_scale_input.value)))\n",
        "\n",
        "            # print(\"Download output video\")\n",
        "            # files.download(output_path)\n",
        "\n",
        "        finally:\n",
        "            torch.cuda.empty_cache()\n",
        "            for file in [video_path, audio_path]:\n",
        "                if os.path.exists(file):\n",
        "                    os.remove(file)\n",
        "\n",
        "run_button.on_click(on_run_button_click)\n",
        "widgets_box = widgets.VBox([video_upload, audio_upload, seed_input, num_steps_input, guidance_scale_input, video_scale_input, output_fps_input, run_button, output_display])\n",
        "display(widgets_box)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XLoD3kfbsfLv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}